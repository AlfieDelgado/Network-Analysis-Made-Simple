{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "So... you've got some interesting property of the network uncovered. Is it real? How can you trust that what you've found **didn't arise by random chance**?\n",
    "\n",
    "One useful way of thinking by using generative models of random graphs. By \"generative\" and \"random\", we mean that the graph was generated using some statistical random model underlying it. This is essentially in the \"Bayesian\" tradition of modelling.\n",
    "\n",
    "The alternative is a non-parametric way of thinking. This is where we don't assume some model that generated the data, and instead performs randomization on the data on hand to calculate statistics. Here, we assume that our randomization procedure is an appropriate random model for the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics Primer\n",
    "\n",
    "**Discrete Distributions:**\n",
    "\n",
    "- Bernoulli: probability p of success in 1 try (e.g. one flip of coin).\n",
    "- Binomial: probability p of success given n number of tries. `n * bernoulli trials` follows binomial distribution.\n",
    "- Poisson: processes with a per-unit rate.\n",
    "\n",
    "**Continuous Distributions:**\n",
    "\n",
    "- Uniform: equal probability over the range of probable values. Can also be made discrete.\n",
    "- Normal: everyone's favourite.\n",
    "\n",
    "We can also make up an arbitrary distribution of our own. :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Test of Significance of Busy Routes\n",
    "\n",
    "If we think back to the graph made in the previous notebook, what kind of process might one imagine that gave rise to the data?\n",
    "\n",
    "**brainstorm session...**\n",
    "\n",
    "Group work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete uniform distribution over all routes\n",
    "\n",
    "Assumptions of this model:\n",
    "\n",
    "1. Riders choose start station with uniform probability.\n",
    "2. They then choose a destination station with uniform probability.\n",
    "3. They ride it and the data are recorded.\n",
    "\n",
    "Under this model, what is the distribution of number of rides taken throughout the ? We can probably solve this analytically, but since we have ultra-cheap computational capabilities at our fingertips, might as well do it the brute-force way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.read_gpickle('datasets/divvy_2013/divvy_graph.pkl')\n",
    "total_trips = sum([d['count'] for _,_,d in G.edges(data=True)])\n",
    "print(total_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Calculate the expected number of trips between any two stations, assuming self-loops are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(total_trips) / len(G.nodes()) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Can you plot a histogram of the number of trips taken on each route?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "num_trips = [d['count'] for _,_,d in G.edges(data=True)]\n",
    "\n",
    "plt.bar(Counter(num_trips).keys(), Counter(num_trips).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Can you figure out the 2.5th, 97.5th, and 100th percentile of this distribution?\n",
    "\n",
    "Hint: You may wish to use `numpy`'s `percentile` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.percentile(num_trips, [2.5, 97.5, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the interval between the 2.5th to the 97.5th percentile effectively gives you a centered 95% mass of the distribution. Knowing this range can be quite useful in other data analysis cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Class Exercise\n",
    "\n",
    "Together, we will implement a random model for the number of trips that are taken between two stations.\n",
    "\n",
    "In this procedure, we will copy the nodes graph `G` into a new graph `G_random`. This can be done by:\n",
    "\n",
    "    G_random = nx.Graph()\n",
    "    G_random.add_nodes_from(G.nodes(data=True))\n",
    "    \n",
    "Following that, we will manually map-reduce this computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the nodes from G.\n",
    "G_random = nx.Graph()\n",
    "G_random.add_nodes_from(G.nodes(data=True))\n",
    "G_random.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the procedure by brute force. You will find it takes a bit of time.......... but because we have so many people \n",
    "# in the class, we can brute force parallelize this :-).\n",
    "from random import sample, choice\n",
    "import math\n",
    "\n",
    "n = 40 # the total number of students with Python 3.4 installed.\n",
    "\n",
    "for i in range(math.ceil(total_trips/n)):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    n1 = choice(G_random.nodes())\n",
    "    n2 = choice(G_random.nodes()) #note: n1 and n2 might well be the same nodes.\n",
    "    if (n1, n2) not in G_random.edges():\n",
    "        G_random.add_edge(n1, n2, count=0)\n",
    "    else:\n",
    "        G_random.edge[n1][n2]['count'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_id = 1 # change this number to the ID given to you.\n",
    "nx.write_gpickle(G_random, 'datasets/divvy_2013/divvy_random{0}.pkl'.format(your_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graphs with randomly re-distributed trip counts as a list of graphs.\n",
    "import os\n",
    "\n",
    "def is_pkl(filename):\n",
    "    \"\"\"\n",
    "    Checks if a file is a pickled graph.\n",
    "    \"\"\"\n",
    "    if filename.split('.')[-1] == 'pkl':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_divvy_random_graph(filename):\n",
    "    \"\"\"\n",
    "    Checks if it's a Divvy graph.\n",
    "    \"\"\"\n",
    "    if 'divvy_random' in filename:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Load the data into a list of graphs.\n",
    "divvy_random_graphs = []\n",
    "for f in os.listdir('datasets/divvy_2013'):\n",
    "    if is_pkl(f) and is_divvy_random_graph(f):\n",
    "        g = nx.read_gpickle('datasets/divvy_2013/{0}'.format(f))\n",
    "        divvy_random_graphs.append(g)\n",
    "        \n",
    "print(len(g.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of counts in the simulated re-distributed set of trips.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "G_random_master = nx.Graph()\n",
    "\n",
    "matrix_master = np.zeros((300, 300)) # shape of matrix is n_nodes by n_nodes\n",
    "for g in divvy_random_graphs:\n",
    "    # Inspired by Jake VDP's talk on using numpy operations to speed up code...\n",
    "    # Recall that graphs can be expressed as a matrix. \n",
    "    m = nx.to_numpy_matrix(g, weight='count') # can specify what number will be used in each numpy cell.\n",
    "    # Sum up the matrices, in a vectorized fashion.\n",
    "    matrix_master += m\n",
    "    \n",
    "    # Note: This is much faster compared to iterating over all the edges. If you deal with large graphs,\n",
    "    # then practically speaking, it may be better to work with matrices rather than graph objects.\n",
    "    \n",
    "# Reshape the matrix to make it easy for plt.hist to handle it.\n",
    "data = matrix_master.reshape(300**2)\n",
    "# plt.hist(data) # OR\n",
    "plt.bar(Counter(data).keys(), Counter(data).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an attempt at writing a numpy-vectorized version of the simulation.\n",
    "\n",
    "Once again, this is inspired by Jake VDP's PyCon talk on using numpy.\n",
    "\n",
    "The core idea here is as such:\n",
    "\n",
    "1. Assume all possible edges had a unique index.\n",
    "2. We can store this in an array of size n_nodes^2.\n",
    "3. We can generate random integers in a second array of size `total trips`, but with maximum value `edges`.\n",
    "4. We then create a histogram using `np.histogram(trip_edges, bins=num_edges+1)`. This returns two arrays:\n",
    "    1. an array with the number of trips in each edge\n",
    "    2. an array with the bin numbers (representing the edges).\n",
    "\n",
    "This here will be much faster than brute-force iteration because we use `numpy` functions.\n",
    "\n",
    "Special thanks to Mauris Van Hauwe on Stack Overflow: http://stackoverflow.com/questions/29578781/how-to-vectorize-simulation-of-distributing-coins-in-numpy/29578883#29578883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of possible edges.\n",
    "edges = len(G.nodes())**2\n",
    "\n",
    "# Recall that the total trips was recorded in the variable total_trips\n",
    "total_trips\n",
    "\n",
    "# coins = 800000\n",
    "# slots = 900000\n",
    "\n",
    "trip_edges = np.random.randint(edges, size=total_trips) \n",
    "trips_in_each_edge = np.histogram(trip_edges, bins=np.arange(edges+1))[0]\n",
    "trips_in_each_edge\n",
    "plt.hist(trips_in_each_edge)\n",
    "print(np.mean(trips_in_each_edge), np.var(trips_in_each_edge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think about it...**\n",
    "\n",
    "Given the distribution of trip counts in the randomly re-distributed trips, what can we infer about the popularity of certain routes? Are they likely to have shown up in this random model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
